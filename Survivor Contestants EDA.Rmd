---
title: "Survivor (TV Series) Players - Exploratory Data Analysis and Modelling"
author: "Jonas Ho Jia Hao"
date: "23/8/2019"
output: 
  html_document:
    code_folding: hide
    theme: readable
---

<style type="text/css">

h1.title {
  text-align: center;
}
h4.author {
  text-align: center;
}
h4.date {
  text-align: center;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 9.5)
options(width = 90)
```

# {.tabset .tabset-pills}

I was watching Survivor Season 38: Edge of Extinction and I became curious about the characteristics of the players. It felt to me as if many players over the years had vibes signalling that they come from California (Hollywood vibes) as opposed to East Coast vibes. So naturally I wondered about the proportions and how the players had been casted for the show.
<br>

As such, the motivation for this project is based on the assumption that I am able to discern the differences between The West Coast and The East Coast which, in reality, is probably a shaky assumption.
<br>
*(Some time ago in history, when there was a 'The East Coast vs The West Coast' discussion, both Tupac and Biggie died; RIP)*

Despite the shaky assumption, I did a Google search and that led me to finding players data from a post on this webpage:
<br>
<https://www.tapatalk.com/groups/survivorsucks/master-list-recruits-applicants-others-all-seasons-t61049-s20.html>.
<br>
The data covers Season 1 to Season 19.

I later needed longitude-latitude coordinates that can provide me with (at least somewhat) centered location coordinates for each state so that I can plot labels on the heat map visibly. I found these information on this webpage:
<br>
<https://inkplant.com/code/state-latitudes-longitudes>

I first:
<br>

1. Cleaned and manipulated the data for exploration.
<br>

2. Explored the age variable.
<br>
What is the age distribution for each season and also across all the seasons?
<br>

3. Explored the gender proportions.
<br>
What is the proportion of the different genders for each season and also across all the seasons?
<br>

4. Explored the home states of players.
<br>
Where do players come from?
<br>

5. Explored the mode proportions.
<br>
What are the proportions for if the players were "Applicants" or if they were "Recruited" through connections?
<br>

6. Modeled the finishing position for players.
<br>
Are we able to explain a player's finishing position in a game in general? 
<br>
Are we able to explain a player's probability of reaching The Merge?
<br>

7. And finally, created a Tableau Dashboard as a companion to the analysis.
<br>

## Survivor Game play
<br>
<br>
In the most basic and default form:
<br>

The game lasts for 39 days on an island and there are 16 to 20 players per game.
<br>

The players are divided into 2 or 3 tribes at the start of the game.
<br>

The tribes will compete in challenges and one player from the losing tribe will be voted out of the game on the night of that challenge. This carries on for the first 20 (approximate) days.
<br>

After the first 20 days, the remaining players will merge into a single tribe. This activity is called 'The Merge'.
<br>

The players will henceforth compete in challenges as individuals and one player will be voted out of the game on the night of that challenge. The winner of that challenge cannot be voted for on that night. This carries on until there are 2 (or 3) players remaining.
<br>

The players voted out of the game after The Merge will return to the game as 'Jury Members' on voting nights to watch the pre-voting discussions between the host and the remaining players.
<br>

At the end, the Jury Members will vote to decide which of the 2 (or 3) remaining players deserves to be the winner of the game.
<br>

The winner takes home $1,000,000 and earns the title of 'Sole Survivor'.
<br>
<br>
<br>
<br>

## 1. Data
<br>
<br>
Import data and view data.
```{r warning = FALSE, message=FALSE}
library(tidyverse)
library(readxl)

surv_players <- read_excel("survivor_contestants.xlsx",
                               col_types = c("text", "text", "numeric",
                                             "text", "text", "text", "text"))

DT::datatable(surv_players, 
              options = list(searching = F,
                             pageLength = 20,
                             initComplete = htmlwidgets::JS(
                               "function(settings, json) {",
                               "$(this.api().table().header()).css({'background-color': '#000',
                               'color': '#fff'});",
                               "}")
                             )
              )
```
<br>

Looks like the column names are jumbled. Let's fix this first by changing the column names.
<br>
Now we see that the columns are:
```{r warning = FALSE, message=FALSE}
colnames(surv_players) <- c("serial", "name", "age", "sex", "city", "state", "mode")


DT::datatable(surv_players, 
              options = list(searching = F,
                             pageLength = 20,
                             initComplete = htmlwidgets::JS(
                               "function(settings, json) {",
                               "$(this.api().table().header()).css({'background-color': '#000',
                               'color': '#fff'});",
                               "}")
                             )
              )
```
<br>

* serial: records the Season number and the placing of the players, where S1 refers to Season 1 and 16 means that the player was the first to be voted out (for a 16-person season) or finished at the last place (Sorry Sonja :[ - the first person voted out in the first season of an epic TV Series). The season number would need to be mutated into a new column.
<br>

* name: records the location of the filming and the name of the player. For example, we see Borneo on the first row which is the location of the filming for Season 1. The name of the filming location would need to be mutated into a new column.
<br>

* age: records the age of the player at the start of the filming.
<br>

* sex: records the gender of the player.
<br>

* city: records the hometown from which the player is from.
<br>

* state: records the abbreviated (2-letter) state from which the player is from.
<br>

* mode: records whether the player was an "Applicant" of the player was "Recruited"
<br>
<br>

For example - The Season 1 winner is Richard Hatch and 4th place is Sue Hawk. Richard hatch was 39 years old during the filming, he is a male from Newport, Rhode Island, and he was an applicant as opposed to being recruited. Richard and Sue later met again in Season 8, the All-Star season and had some drama regarding sexual harassment between them.
<br>
<br>

Take a sneak peak at age.
<br>
<br>

The total age distribution is heavily right skewed implying that the overall median age is lower than the overall mean age.
<br>

Nevertheless, the median age (30 years old) is higher than I had expected (which was high-20's years old). The minimum was at 20 years of age; this has been beat recently by Will and Michael from Season 33 and Season 36 who were 18 when they were players.
<br>

Who is the player that is 76 years old?
```{r warning = FALSE, message=FALSE}

summary(surv_players$age)

ggplot(surv_players, aes(x = as.numeric(age))) + geom_histogram(fill = "grey", col = "black") +
  theme_bw() +
  labs(title = "Total Age Distribution",
       x = "Age",
       y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5))
```
<br>
It's Rudy Boesch. Rudy Boesch was a player twice, 4 years apart, so about 8 seasons apart. Which seasons, I wonder?
```{r warning = FALSE, message=FALSE}
surv_players %>%
  arrange(desc(age))
```
```{r message=FALSE, warning=FALSE}
surv_players %>%
  filter(name == "Rudy Boesch")
```
Ah, it is not so easy to find out the season numbers as the season numbers are embedded as rows in the serial column. This is why we need a **tidy** data set!
<br>
<br>

In order to have a tidy dataset, each column should only hold a variable. In this case, the serial column holds two variables: season number and player position. Similarly, the name column holds two variables: filming location and name of the player.
<br>

We will need to move the serial number variable and the filming location variable into two new separate columns. (Side note: Recently, filming location has been permanently settled at Fiji - which makes a lot of logistical sense)
<br>
<br>

The serial column is especially messy. It contains the season number amongst the positions of each player, special characters, and additional text.
```{r}
unique(surv_players$serial)
```
In order to facilitate further cleaning we need to deal with the additional text pattern (i.e. [/font]) first. We can remove the pattern that all start with '[' to every column (not just the serial column). We then look at the new unique values for serial.
<br>
```{r message = FALSE, warning=FALSE}
surv_players_clean <- surv_players %>%
  # serial
  separate(serial, c("serial", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # name
  separate(name, c("name", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # age
  separate(age, c("age", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # sex
  separate(sex, c("sex", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # city
  separate(city, c("city", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # state_s
  separate(state, c("state", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  # mode
  separate(mode, c("mode", "to remove"), sep = "\\[") %>%
  select(., -"to remove") %>%
  mutate(serial = str_replace(serial, "2\\*", "2"),
         serial = str_replace(serial, "5\\*", "5")) %>%
  # player '*' did not participate in the end
  filter(serial != "*") %>%
  mutate(age = as.double(age))
unique(surv_players_clean$serial)
```
<br>

Looks great!
<br>
<br>

Now we need to find the index numbers of the last entry for each season. Then we need to find the difference from the last entry to the first entry of each season. We do this because we need to know how many rows make up a season. By knowing how many rows make up a season, we can know how many values to paste into the columns.
<br>

We can find the last entry by checking the index number for the winner of that season. Notice that there are only 18 elements in the vector while we should get 19 (as there are 19 seasons). This is because the last entry for season 19 is 'NA'. We will need to manually add the index number of the last row.
<br>

Index numbers.
```{r warning = FALSE, message=FALSE}
index <- which(surv_players_clean$serial == as.character(1))
index
```
Index numbers length.
```{r}
length(index)
```
Add last entry to the vector of index numbers and find the length.
```{r warning = FALSE, message=FALSE}
updated_index <- c(index, length(surv_players_clean$serial))

length(updated_index)
```
<br>

We can difference the vector of indexes to find the number of rows per season. But in order not to lose information on the first index, we will need to manually include that in.
<br>

Number of rows per season.
```{r warning = FALSE, message=FALSE}
updated_index_diff <- c(updated_index[1], diff(updated_index))
updated_index_diff
```
Number of seasons.
```{r}
length(updated_index_diff)
```
<br>
<br>

Create a new vector that holds the season numbers and its repetitions. The amount of times the season number is repeated is based on the values in the vector telling us how many rows there are per season.
<br>

View the vector of season numbers and its repetitions.
```{r warning = FALSE, message=FALSE}
season <- c()

for (i in 1:length(updated_index_diff)) {
 season <- c(season, rep(i, (updated_index_diff[i])))
}

season
```
Append this vector as a new column into our original dataset and view the dataset. We see that there is now a new season variable.
```{r}
surv_players_clean$season <- as.factor(season)

glimpse(surv_players_clean)
```
<br>
<br>

Now we can work on separating the filming location and the name of the player from the name column.
<br>

We first need to find the index values where the filming location exists.
<br>

We note that the name of the filming location is always at the start of a chunk of rows that represent that season. Hence, by using the previous index values we have found of the winners, we just need to add 1 index placing and that index value will be where the filming location name exists (for a visual example: see row 34 and row 35 of the dataset.)
<br>

By doing this, the last entry will not make sense and we need to manually include the first entry (Borneo). Hence we will take the previous vector of index values and add 1 to it, then we will remove the last entry and add our first entry which is at row 1 (for Borneo).
<br>

We see the index values of the filming locations here.
```{r warning = FALSE, message=FALSE}
updated_index_2 <- c(1, updated_index + 1)
updated_index_2 <- updated_index_2[-length(updated_index_2)]
updated_index_2
```
<br>

Now we can use these index numbers to find the filming locations and their seasons. We do this by iteratively filling up a list of filming locations after searching for them in our dataset.
<br>

Finally we create a subset and view only the filming location and its corresponding season number. 
```{r warning = FALSE, message=FALSE}
location <- list()

for (i in 1:length(updated_index_2)) {
 location[[i]] <- surv_players_clean[updated_index_2[i], ]
}

location <- do.call("rbind", location)

location <- location %>%
  select(name, season)

location
```
<br>

Next, we will need to create a new vector that holds the location names.
<br>

In order to create that vector, we need to first create a dictionary that will hold the Key-Value pairs Season-Filming location. This is so that when I call season 1, I can get an output of "Borneo"
<br>
```{r warning = FALSE, message=FALSE}
library(hash)
hash <- hash(as.vector(location$season), location$name)
hash
```
Creating the location vector is similar to how we created the vector for the season numbers above. This time I use the dictionary to automatically use the value from the key-Value pair, and then used the key to access the vector of index that holds the information about the number of rows per season.
```{r}
location_col <- c()

for (i in 1:length(location$season)) {
  location_col <- c(location_col, rep(hash[[toString(i)]], updated_index_diff[i])) 
}
```
The vector of location names.
```{r}
location_col

surv_players_clean$location <- location_col
```
<br>

Now all we need to do is update this new location column into the current dataset and remove the rows that have been holding the season number information and the filming location information.
<br>

We can view our new dataset. Notice that we now have 2 new columns: season and location, and the rows holding the S1:Borneo (Season:location) information is removed. 
<br>
```{r warning = FALSE, message=FALSE}

surv_players_clean <- surv_players_clean[-updated_index_2, ] 

DT::datatable(surv_players_clean, 
              options = list(searching = F,
                             pageLength = 20,
                             initComplete = htmlwidgets::JS(
                               "function(settings, json) {",
                               "$(this.api().table().header()).css({'background-color': '#000',
                                 'color': '#fff'});",
                               "}")))
```
<br>
This is exactly what we need for now!
<br>
<br>
<br>
<br>

## 2. Age
<br>
<br>
**What is the age distribution for each each season and also across all the seasons?**
<br>
<br>


Finally we can now find out details for Rudy Boesch!
<br>

We can see below that he was in Season 1 and Season 8, which are 8 seasons apart as suspected. He finished behind at 17th place in Season 8 despite being the 2nd runner-up for Season 1 (It was the all-star season and therefore he was playing against great players like Boston Rob. I can't say how Rudy was voted out, but there was also a possibility that he already had a target on his back going into the game). Notably it was also in this season that the Boston Rob and Amber Brkich romance started.
```{r warning = FALSE, message=FALSE}
surv_players_clean %>%
  filter(name == "Rudy Boesch")
```
<br>
<br>
<br>

I have now become curious about the distribution of age over time. I wonder if there is a difference in the distribution of age across the seasons. We can explore this by the boxplot below.
<br>

Unfortunately, age data isn't available for Season 18 and Season 19.
<br>

Each boxplot represents the age distribution per season, up until season 17. It looks like the median age hovers around 30 years old, with Season 9 and Season 17 having tighter distributions around their middle 50% values.
```{r}
ggplot(na.omit(surv_players_clean), 
       aes(x = season,
           y = age)) + 
  geom_boxplot(fill = "#FFCC99") +
theme_bw() +
  labs(title = "Boxplot of Survivor players from Season 1 to Season 17",
       x = "Seasons",
       y = "Age") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(limits = c(20, 80), breaks = c(seq(from = 0, to = 80, by = 10)))
```
<br>
<br>

The variance across the seasons are computed below. Notably variance in age for season 1 is relatively high, this is backed up graphically by the 3 (far-away) outliers seen on the boxplot for season 1. The variance in age is considerably lower in season 13. This can also be seen graphically as it has the tightest distribution amongst the plots with no outliers.
```{r}
print(paste("Variance:", by(surv_players_clean$age, surv_players_clean$season, var)))
```
<br>
We can test if the differences in variances across the seasons are significant using the levene test. This can give us a good idea of the similarity or dissimilarity in our data between seasons.
<br>

The Null for the levene test cannot be rejected (p-value = 0.823) implying that variances of age across the seasons are not significantly different from one another. In other words we have homoscedastic variance, a convenient property for further tests!
```{r}
car::leveneTest(as.numeric(age) ~ season, data = surv_players_clean)
```
<br>
<br>

Having homoscedastic variance satisfies only one of two assumptions required to run a one-way ANOVA (pfft, these parametric tests and their assumptions, aimirite?) to compare means of ages across the seasons. The other assumption required is the assumption of normality. The means across the seasons are computed below. 
```{r}
print(paste("Mean:", by(surv_players_clean$age, surv_players_clean$season, mean)))
```
<br>
Looking at the histogram plots of ages across the seasons below, it is entirely obvious that age does not follow a normal distribution, at least not with the sample sizes that we have - only about n = 17 per season.
```{r warning=F, message=F}
facet_labels <- c()

for (i in 1:length(updated_index)) {
  facet_labels <- c(facet_labels, paste("Season", toString(i)))
}

names(facet_labels) <- 1:19

ggplot(data = na.omit(surv_players_clean), aes(x = age)) + geom_histogram(binwidth = 5, fill = "#FFCC99", col = "black") + facet_wrap(~ season, labeller = labeller(season = facet_labels)) +
  theme_bw() +
  labs(title = "Distribution of Age for each Season",
       x = "Age",
       y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5))
  
```
<br>

Fortunately, a one-way ANOVA is quite robust and so it is not sensitive to deviations from normality. The concern about not satisfying normality becomes serious only if there is borderline rejection of the null hypothesis; if p-value is just below 0.05.
<br>

```{r}
aov(age ~ season, data = surv_players_clean)
summary(aov(age ~ season, data = surv_players_clean))
```
<br>

Based on the ANOVA summary output above we cannot reject the null (p-value = 0.9); there is no significant differences between means across all the seasons.
<br>
<br>

Hence we have 3 results from the above.
<br>

1) Data for players' ages across all seasons are not significantly different in their means,
<br>

2) Data for players' ages across all seasons are not significantly different in their variances,
<br>

3) The casting director is on point(!) with player selection.
<br>
<br>
<br>
<br>

## 3. Gender
<br>
<br>
**What is the proportion of the different genders for each season and across all the seasons?**
<br>
<br>

Based on impressions, the gender proportion has always been even.
<br>

There has also been 'Men vs Women' seasons in survivor history:
<br>

Season 6: Amazon (winner = Jenna Morasca, Female)
<br>

Season 9: Vanuatu (winner = Chris Daugherty, Male)
<br>

Season 12: Panama (winner = Aras Baskaukas, Male)
<br>

Season 24: One World (winner = kim Spradlin, Female)
<br>
<br>

The proportion plot below confirms my anecdote.
```{r warning = FALSE, message=FALSE}
ggplot(surv_players_clean, aes(x = season, fill = sex)) + geom_bar(position = "fill", color = "black") +
  theme_bw() +
  labs(title = "Proportion of Gender Across Seasons",
       x = "Seasons",
       y = "Proportion",
       fill = "Sex") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.5, 1), labels = c("0%", "50%", "100%")) +
  scale_fill_manual(values = wesanderson::wes_palette("Moonrise2", n = 3))
```
<br>
<br>

A strange entry exists: "F*". We should check if there is a reason behind this entry with a special character.
```{r}
glimpse(surv_players_clean %>% filter(sex == "F*"))
```
It is Erin collins from Season 5, thought to be a transvestite because of seemingly having an Adam's apple!
<br>
<br>
<br>
<Br>

## 4. Home states
<br>
<br>
**Where do players come from?**
<br>
<br>

We can also explore the state from which the players come from.
<br>

From sorting, we see that the top home state is California with 81 players, the 1st runner-up is New York with 28 players, and finally the 2nd runner-up is Texas with 16 players.
```{r warning = FALSE, message=FALSE}
head(surv_players_clean %>%
  count(state) %>%
  arrange(desc(n)), n = 10)
```
<br>

To visualize the heat map, we will first need coordinates information about the states. Fortunately this data is readily available in R.
<br>

States (first 5 rows):
```{r message = FALSE}
states <- map_data("state")
head(states, n = 5)

```
<br>

In our data set, the column that holds the state information has been abbreviated into two-letter shortcuts. We will use the 'abbr2state' function from the openintro package to convert these to long names, and then append this vector as a new column called 'region' to our dataset.
<br>
*(This package is the companion to a free online introductory statistics textbook, written by Professor Mine çetinkaya-rundel from Duke)*
```{r} 
state_long <- tolower(unlist(lapply(surv_players_clean$state, openintro::abbr2state)))
surv_players_clean$region <- state_long
glimpse(surv_players_clean)
```
<br>

To create the main dataset from which we will plot the heat map, we will need to join the count information with the States dataset that we imported from R above previously.
<br>

The dataset looks like this:
```{r}
# new data frame for plotting
p <- surv_players_clean %>%
  count(region) %>%
  arrange(desc(n)) %>%
  rename("Count" = n)

p1 <- states %>%
  left_join(p, by = "region")

p2 <- p1[order(p1$order),] 

head(p2, n = 5)
```
<br>

Then in order to have the dataset that contains the longitude-latitude coordinates, we will need to join the longitude-latitude data sourced online with the data set containing the counts and state names. With this dataset, we can plot the state name and the count of players from that state onto the main heat map as another layer using the coordinates information.
<br>
```{r}
lon_lat_centerd <- read_excel("centered_long_lat_states_usa.xlsx")
colnames(lon_lat_centerd) <- c("region", "lat", "long")
lon_lat_centerd$region <- tolower(lon_lat_centerd$region)

p3 <- p %>%
  left_join(lon_lat_centerd, by = "region")

p3 <- p3 %>%
  filter(!is.na(region))

p3$region <- unlist(lapply(p3$region, openintro::state2abbr))

head(p3)

# Manually adjusting labels

p3.1 <- p3 %>%
  mutate(long = case_when(region == "WA" ~ long + 0.6,
                          region == "OR" ~ long + 0.3,
                          region == "NE" ~ long - 0.3,
                          region == "KS" ~ long - 0.3,
                          region == "LA" ~ long - 0.5,
                          region == "MI" ~ long - 0.1,
                          region == "MN" ~ long - 0.1,
                          region == "FL" ~ long + 0.1,
                          region == "TX" ~ long - 0.5,
                          region == "NE" ~ long - 0.1,
                          region == "KS" ~ long - 0.4,
                          region == "MA" ~ long + 2,
                          region == "NJ" ~ long + 0.5,
                          long == long ~ long),
         lat = case_when(region == "NV" ~ lat + 1,
                         region == "UT" ~ lat - 1,
                         region == "NY" ~ lat + 1,
                         region == "CT" ~ lat - 1.5,
                         region == "NJ" ~ lat - 1,
                         region == "RI" ~ lat - 1,
                         lat == lat ~ lat))
```  
<br>

Now, we can finally visualize the heat map by plotting the main map and then layering it to include label values.
```{r}
ggplot(p2, aes(x = long, y = lat, group = group)) + 
  geom_polygon(aes(fill = Count)) +
  geom_path() +
  scale_fill_gradientn(colours = rev(heat.colors(10)),na.value = "grey90") +
  coord_map() +
  theme_bw() +
  labs(title = "Heat Map of Home states",
       x = "Longitude",
       y = "Latitude") +
  theme(plot.title = element_text(hjust = 0.5)) +
  geom_text(data = p3.1, aes(x = long, y = lat + 0.4, group = NA, label = region), 
            size = 3.5) +
  geom_text(data = p3.1, aes(x = long, y = lat - 0.3, group = NA, label = Count),
            size = 2.8)
```
<br>

We see that most players on the show hail from California (81). The next state with the highest number of players is New York (28), and finally Texas (16). Some states (as of Season 19) have not been represented.
<br>

As suspected at the start of the analysis, most players do indeed come from California and hence it was possible to sense the "Hollywood vibes". As it turns out, my assumption is not a shaky one in reality after all!
<br>

We do not have data on the rejected players and therefore would not be able to comment on the casting decisions. But there is definitely some selection bias; residents of California are more likely to apply to be on a TV show because of their proximity to and the influence of Hollywood.
<br>
<br>
<br>
<br>

## 5. Mode
<br>
<br>
**What are the proportions for if the players were "Applicants" or if they were "Recruited" through connections?**
<br>
<br>

Another interesting variable that we can look at is the mode by which the players were first introduced to the casting crew.
<br>

The "Application" value means that the player applied cold and not through any connections. The "Recruited" value on the other hand means that the player had been encouraged to apply by someone on the crew or was recruited directly to join the cast.
<bR>

We first create the dataset from which we will plot our data by creating a binary outcome variable for 1 = "Applicant" or for 0 = "Recruited".
<br>
```{r warning = FALSE, message=FALSE}
prop_mode <- surv_players_clean %>%
  # mode_binary variable
  separate(mode, c("mode", "to remove"), sep = "Applicant") %>%
  select(., -"to remove") %>%
  mutate(mode_binary = ifelse(mode == "", 1, 0)) %>%
  select(., -"mode")
glimpse(prop_mode)
```
<br>

We then plot the proportions.
```{r}
ggplot(prop_mode, aes(x = season, fill = as.factor(mode_binary))) + geom_bar(position = "fill", color = "black") +
  theme_bw() +
  labs(title = "Proportion of 'Applicant' vs 'Recruited' Across Seasons",
       x = "Seasons",
       y = "Proportion",
       fill = "Mode") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.25, 0.5, 0.75, 1), labels = c("0%", "25%", "50%", "75%", "100%")) +
  
  scale_fill_manual(labels = c("Recruited", "Applicant"), values = wesanderson::wes_palette("Moonrise2", n = 2))
```
<br>

We note from above that as the show progressed, more and more players have been recruited as opposed to have been from open applications.
<br>

All players in Season 8 were recruited because these were All-Star players from previous seasons.
<br>

It is quite interesting to note how players were recruited.
<br>

* Some came from other TV Shows such as the The Amazing Race and Big Brother,
<br>

* Some got recruited through networks with past players, and finally
<bR>

* some got recruited through networks with the crew working on the show.
<br>
<br>
<br>

Here is the list of unique recruitment comments:
```{r warning = F}
tmp <- surv_players_clean %>%
  # mode_binary variable
  separate(mode, c("mode", "to remove"), sep = "Applicant")

tmp <- tmp %>%
  filter(!(mode %in% c("", "n/a", "")))

tmp_2 <- tmp$mode[!duplicated(tmp$mode)]

tmp_2
```
<br>
<br>
<br>
<br>

## 6. Regression
<br>
<br>
**Are we able to explain a player's finishing position in a game in general?**
<br>
<br>

**Are we able to explain a player's probability of reaching The Merge?**
<br>
<br>

**Multiple Linear Regression**
<br>

We can run a linear regression to model the expected place of a player given the variables available.
<br>
<br>

First we will need to do some transformations:
<br>

* Mode: "Applicant" = 1 or "Recruited" = 0
<br>

* sex: "M" = 1 or "F" = 0
<br>

* age: convert as numeric
<br>

* serial: convert as numeric
<br>

* state: segregate into region (West, Midwest, South, East) and create a new variable with reference to the U.S. Census Bureau Regions and Divisions seen below.
![Image of Divisions](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Census_Regions_and_Division_of_the_United_States.svg/1280px-Census_Regions_and_Division_of_the_United_States.svg.png)
<br>

Results from transformation:
```{r warning= F}
model_df <- surv_players_clean %>%
  # mode_binary variable
  separate(mode, c("mode", "to remove"), sep = "Applicant") %>%
  select(., -"to remove") %>%
  mutate(mode_binary = ifelse(mode == "", 1, 0)) %>%
  select(., -"mode") %>%
  mutate(mode_binary = as.factor(mode_binary)) %>%
  # sex_binary variable
  mutate(sex_binary = ifelse(sex == "M", 1, 0)) %>%
  mutate(sex_binary = as.factor(sex_binary)) %>%
  # serial remove NA and Special Character (i.e *)
  na.omit() %>%
  # age as numeric
  mutate(age = as.double(age)) %>%
  # serial as numeric
  mutate(serial = as.double(serial)) %>%
  mutate(region = case_when(state %in% c("WA", "OR", "CA", "NV", "ID", "AZ", "MT", "WY", "UT", "CO", "NM") ~ "West",
                              state %in% c("TX", "OK", "AR", "LA", "MS", "AL", "TN", "KY", "WV", "DC", "MD", "DE", "VA", "NC", "SC", "GA", "FL") ~ "South",
                              state %in% c("ME", "NY", "NH", "VT", "PA", "NJ", "CT", "MA", "RI") ~ "East",
                              state %in% c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH") ~ "Midwest"))
glimpse(model_df)
```
<br>

We can now fit the model and print the outputs.
<br>

We are regressing serial on age, mode, sex, and region.
```{r}
model_df$region <- factor(model_df$region, levels = c("East", "South", "West", "Midwest"))

fit <- lm(serial ~ age + mode_binary + sex_binary + region, data = model_df)

anova(fit)

summary(fit)
```
<br>
From the summary output we note that the age, mode, and sex of the players are not significant in explaining their serial numbers (placing in the game).
<br>

The intercept holds information for a female player who has been recruited and comes from the East with age equals 0. If a player's home region is from the South, the player's placing in the game will significantly increase by about 2 (on average) relative to if the player's home region is from the East.
<br>

Recall that a serial of 1 refers to being the winner, hence a player from the South is expected to do significantly worse than a player who comes from the East by 2 places. 
<br>
<br>

Given the results above, we should view some diagnostic plots below to check for validity of these results.
```{r warning=F, fig.height=8}
par(mfrow=c(2,2))
plot(fit)
```
<br>

1) Linearity assumption and expectation of residuals is zero assumption:
<br>

The residuals in the Residuals vs Fitted plot look like they are randomly dispersed about the value 0 as the fitted values increases. This implies that there is no non-linear relationship between the regressors and the outcome, hence the assumption of linearity between the outcome and the regressors is not violated. Another implication from interpreting the plot is that the expectation of residuals is zero, hence the model fit is correct in the long run.
<br>
<br>

2) Homoscedasticity of residuals:
<br>

The spread of residuals in the Scale-Location plot look random without any discernible patterns or shapes as fitted values increase. Hence the  homoscedastic residuals condition is not violated.
<br>
<br>

The diagnostics above confirm that the results from the linear regression is valid. 
<br>
<br>

Side notes:

* Normality of residuals:
<br>

The Q-Q plot shows that residuals are symmetric but they also have fatter-than-normal tails. Hence the residuals are not normally distributed. But because we have a large sample size, it should have little impact on further hypothesis testing; the residuals are not non-normal enough to be of concern.
<br>
<br>

* Influential Observations:

The Residuals vs Leverage plot tell us if any influential observations exist. Influential observations are observations that have residuals which are outliers and which significantly influences the model fit. In our case we should not be concerned as none exists. If one exists we should be concerned with the handling of it; removing it might provide us with a better model fit but such an activity must be reported along with an explanation.
<br>
<br>
<br>
<br>

**Logistic Regression**
<br>

Surviving to The Merge and getting *the right to become a Jury Member* (when voted out) is seen as getting to the second and the main stage of the game. And therefore I wonder, can we model the odds of a player surviving until The Merge?
<br>

Surviving to The Merge and getting *the right to become a Jury Member* are usually the same thing, however in Season 4 (Thailand), Season 13 (Cook Islands), Season 14 (Fiji), Season 17 (Gabon), and Season 20 (Heroes vs. Villains), the Jury Phase started before The Merge.
<br>

Hence a more appropriate question would be if we could model the odds of a player getting *the right to become a Jury Member*. Note that the winner and the 1st runner up have never been Jury Members but they did have the *right* to become one (if they had been voted out in the days preceding).
<br>

The data on the number of Jury Members each season are sourced from Wikipedia, I have manually created a dataframe that contains the season number and the number of players who had *the right to become Jury Members*.
```{r}
right2bjury <- tibble(
  season = 1:19,
  num_players = c(9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 12, 12, 10, 10, 10, 9, 12)
)
right2bjury
```
<br>

We can use the information above to create a new binary variable called right2bjury that signals if a player had *the right to become a Jury Member* (1) or not (0).
```{r}
logreg_df <- model_df %>%
  mutate(right2bjury = case_when(season == 1 & serial <= 9 ~ 1,
                                 season == 2 & serial <= 9 ~ 1,
                                 season == 3 & serial <= 9 ~ 1,
                                 season == 4 & serial <= 9 ~ 1,
                                 season == 5 & serial <= 9 ~ 1,
                                 season == 6 & serial <= 9 ~ 1,
                                 season == 7 & serial <= 9 ~ 1,
                                 season == 8 & serial <= 9 ~ 1,
                                 season == 9 & serial <= 9 ~ 1,
                                 season == 10 & serial <= 9 ~ 1,
                                 season == 11 & serial <= 9 ~ 1,
                                 season == 12 & serial <= 9 ~ 1,
                                 season == 13 & serial <= 12 ~ 1,
                                 season == 14 & serial <= 12 ~ 1,
                                 season == 15 & serial <= 10 ~ 1,
                                 season == 16 & serial <= 10 ~ 1,
                                 season == 17 & serial <= 10 ~ 1,
                                 season == 18 & serial <= 9 ~ 1,
                                 season == 19 & serial <= 12 ~ 1),
         right2bjury = ifelse(is.na(right2bjury), 0, 1),
         right2bjury = as.factor(right2bjury))
glimpse(logreg_df)
```
<br>

We can now run a logistic regression to calculate the effects of the explanatory variables on getting *the right to become a Jury Member*.
```{r}
log_fit <- glm(right2bjury ~ age + sex_binary + mode_binary + region, data = logreg_df, family = "binomial")
summary(log_fit)
```
<br>

From the summary output, none of the variables included are significant in explaining whether a player will have *the right to become a Jury Member* or not. The intercept holds information for a female player who has been recruited and comes from the East with age equals 0.
<br>

However, note that if regionSouth had been significant, the estimated odds ratio of a player having *the right to become a Jury Member* if the player is from the South is 0.56 times (= exp(-0.58089)) that of the odds for if the player is from the East; odds of having *the right to become a Jury Member* are reduced if the player is from the South relative to being from the East. This backs up our analysis above for linear regression. Alternatively, the probability of a player from the South having the *the right to become a Jury Member* is about 44% lower [(|0.56 - 1|)*100] than of that of a player from the East.
<br>
<br>

**Discussion:**
<br>

We should recognize that the outcome serial number is an ordinal outcome variable hence some type of ordinal regression will be appropriate. But given that there are many levels in the Serial outcome (20 levels) I have considered the variable serial as a continuous variable. We did lose flexibility by doing so but we saw from the diagnostics that a linear model assumption is not violated. Such an analysis is similar to modelling age in practice.
<br>

Survivor is ultimately a game of social interactions despite the physical and problem-solving challenges that the players compete in. And as such, to build an effective model to explain how far a player can advance into the game, with the variables we currently have, is quite improbable. Watch Yul Kwon in Season 13: Cook Islands to see a great example of how to mix physical abilities, problem-solving skills, and social skills to win the game.
<br>
<br>
<br>
<br>

## 7. Tableau
<br>
<br>
**Tableau companion to analysis.**
<br>

![Tableau Companion](C:/Users/Jonas/Desktop/Survivor Players EDA/Tableau Image - Companion to Analysis.jpg)
<br>
<br>
<br>
<br>

